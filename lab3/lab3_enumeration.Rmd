---
title: "Lab 3: Enumeration"
author: "IMMERSE Training Team"
date: "Updated: `r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    theme: flatly
editor_options:
  markdown:
    wrap: sentence
header-includes:
- \usepackage{wrapfig}     
---

```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri(file.path("figures/immerse_hex.png")), 
               alt = 'logo', 
               style = 'position:absolute; top:0; right:0px; padding:10px;',
               width ="200")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE,
                      message = FALSE,
                      tidy.opts=list(width.cutoff=60)) #Here, I have made it so that when you knit your .rmd, warnings and messages will not show up in the html markdown. 
```

------------------------------------------------------------------------

![](figures/IESNewLogo.jpg){style="float: left;" width="300"}

The Institute of Mixture Modeling for Equity-Oriented Researchers, Scholars, and Educators (IMMERSE) is an IES funded training grant (R305B220021) to support education scholars in integrating mixture modeling into their research.

-   Please [visit our website](https://immerse.education.ucsb.edu/) to learn more.

-   Visit our [GitHub](https://github.com/immerse-ucsb) account to access all the IMMERSE materials.

-   Follow us on [Twitter](https://twitter.com/IMMERSE_UCSB)!

How to reference this workshop: Institute of Mixture Modeling for Equity-Oriented Researchers, Scholars, and Educators (2023).
IMMERSE In-Person Training Workshop (IES No. 305B220021).
Institute of Education Sciences.
<https://immerse-ucsb.github.io/pre-training>

------------------------------------------------------------------------

Load packages

```{r}
library(MplusAutomation)
library(tidyverse) #collection of R packages designed for data science
library(here) #helps with filepaths
library(janitor) #clean_names
library(gt) # create tables
library(cowplot) # a ggplot theme
library(DiagrammeR) # create path diagrams
library(glue)
```

------------------------------------------------------------------------

*Data source*: The dataset used in this example comes from the Longitudinal Study of American Life (LSAL; Miller, 2010), funded by the National Science Foundation (NSF) in 1986. Science attitude items for the LCA were selected based on prior research using the same data (Ing & Nylund-Gibson, 2013, 2017) to create the latent class variable.

```{r, echo=FALSE, eval=TRUE}
tribble(
  ~ "Name",~ "Description",~ "Values",
  "Enjoy","I Enjoy Science","0 = Disagree, 1 = Agree",
  "Useful","Science is Useful in Everyday Problems","0 = Disagree, 1 = Agree",
  "Logical","Science Helps Logical Thinking","0 = Disagree, 1 = Agree",
  "Job","Need Science for a Good Job","0 = Disagree, 1 = Agree",
  "Adult","Will Use Science Often as an Adult","0 = Disagree, 1 = Agree") %>%
  gt() %>%
  tab_header(title = "Binary LCA indicators") %>%
  tab_options(table.width = pct(80)) %>%
  tab_footnote(footnote = "Longitudinal Study of American Life (LSAL)",
               location = cells_title())
```

------------------------------------------------------------------------

```{r, echo=FALSE, eval=TRUE, fig.align='center'}

grViz(" digraph model {

# The `graph` statement - No editing needed

    graph [layout = dot, overlap = true]
 
# Two `node` statements
 
# One for measured variables (box) 

    node [shape=box]
    Enjoy Useful Logical Job Adult;
 
# One for latent variables (circle) 
 
    node [shape=circle]
    lca [label=<Science Attitudes <br/>C<sub>k</sub>>];
    
# `edge` statements
 
    edge [minlen = 2]
    lca -> {Enjoy Useful Logical Job Adult}
 
 }") 
```

------------------------------------------------------------------------

The data can be found in the `data` folder and is called `lsay_subset.csv`.

```{r}
lsay_data <- read_csv(here("lab3","data","lsay_subset.csv")) %>% 
  clean_names() # make variable names lowercase
```

------------------------------------------------------------------------

Proportion of indicators using R:

```{r}
# Set up data to find proportions of binary indicators
ds <- lsay_data %>% 
  pivot_longer(c(enjoy, good, useful, logical, job, adult), names_to = "Variable") 

# Create table of variables and counts
tab <- table(ds$Variable, ds$value)

# Find proportions and round to 3 decimal places
prop <- prop.table(tab, margin = 1) %>% 
  round(3)

# Combine everything to one table 
dframe <- data.frame(Variables=rownames(tab), Proportion=prop[,2], Count=tab[,2])
#remove row names
row.names(dframe) <- NULL

# Make it a gt() table
prop_table <- dframe %>% 
  gt()
prop_table

# Save as a Word doc
gtsave(prop_table, here("lab3", "figures", "prop_table.docx"))
```

------------------------------------------------------------------------

## Enumeration

This code uses the `mplusObject` function in the `MplusAutomation` package and saves all model runs in the `enum` folder.

```{r, eval = FALSE}

lca_6  <- lapply(1:6, function(k) {
  lca_enum  <- mplusObject(
    
    TITLE = glue("{k}-Class"), 
    
    VARIABLE = glue(
      "categorical = enjoy useful logical job adult; 
     usevar = enjoy useful logical job adult;
     classes = c({k});"),
    
    ANALYSIS = 
      "estimator = mlr; 
    type = mixture;",
    
    OUTPUT = "tech11 tech14;",

    usevariables = colnames(lsay_data),
    rdata = lsay_data)
  
  lca_enum_fit <- mplusModeler(lca_enum, 
                               dataout=glue(here("lab3","enum", "LSAL_data.dat")),
                               modelout=glue(here("lab3","enum", "c{k}_lsal.inp")) ,
                               check=TRUE, run = TRUE, hashfilename = FALSE)
})

```

**IMPORTANT**: Before moving forward, make sure to open each output document to ensure models were estimated normally. In this example, the last two models (5- and 6-class models) did not produce reliable output and are excluded. 

------------------------------------------------------------------------

### Table of Fit

First, extract data:

```{r}
output_lsal <- readModels(here("lab3","enum")) 

enum_extract <- LatexSummaryTable(
  output_lsal,
  keepCols = c(
    "Title",
    "Parameters",
    "LL",
    "BIC",
    "aBIC",
    "BLRT_PValue",
    "T11_VLMR_PValue",
    "Observations"
  ),
  sortBy = "Title"
) %>% slice_head(n=4) # Select first four models (Class 1 through 4)


allFit <- enum_extract %>%
  mutate(aBIC = -2 * LL + Parameters * log((Observations + 2) / 24)) %>%
  mutate(CAIC = -2 * LL + Parameters * (log(Observations) + 1)) %>%
  mutate(AWE = -2 * LL + 2 * Parameters * (log(Observations) + 1.5)) %>%
  mutate(SIC = -.5 * BIC) %>%
  mutate(expSIC = exp(SIC - max(SIC))) %>%
  mutate(BF = exp(SIC - lead(SIC))) %>%
  mutate(cmPk = expSIC / sum(expSIC)) %>%
  dplyr::select(1:5, 9:10, 6:7, 13, 14) %>%
  arrange(Parameters)
```

Then, create table:

```{r}
fit_table <- allFit %>%
  gt() %>%
  tab_header(title = md("**Model Fit Summary Table**")) %>%
  cols_label(
    Title = "Classes",
    Parameters = md("Par"),
    LL = md("*LL*"),
    T11_VLMR_PValue = "VLMR",
    BLRT_PValue = "BLRT",
    BF = md("BF"),
    cmPk = md("*cmPk*")
  ) %>%
  tab_footnote(
    footnote = md(
      "*Note.* Par = Parameters; *LL* = model log likelihood;
BIC = Bayesian information criterion;
aBIC = sample size adjusted BIC; CAIC = consistent Akaike information criterion;
AWE = approximate weight of evidence criterion;
BLRT = bootstrapped likelihood ratio test p-value;
VLMR = Vuong-Lo-Mendell-Rubin adjusted likelihood ratio test p-value;
*cmPk* = approximate correct model probability."
    ),
locations = cells_title()
  ) %>%
  tab_options(column_labels.font.weight = "bold") %>%
  fmt_number(c(3:7),
             decimals = 2) %>%
  sub_missing(1:11,
              missing_text = "--") %>%
  fmt(
    c(8:9, 11),
    fns = function(x)
      ifelse(x < 0.001, "<.001",
             scales::number(x, accuracy = .01))
  ) %>%
  fmt(
    10,
    fns = function (x)
      ifelse(x > 100, ">100",
             scales::number(x, accuracy = .01))
  ) %>%  
  tab_style(
    style = list(
      cell_text(weight = "bold")
      ),
    locations = list(cells_body(
     columns = BIC,
     row = BIC == min(BIC[c(1:4)]) # Change this to the number of classes you estimated
    ),
    cells_body(
     columns = aBIC,
     row = aBIC == min(aBIC[1:4])
    ),
    cells_body(
     columns = CAIC,
     row = CAIC == min(CAIC[1:4])
    ),
    cells_body(
     columns = AWE,
     row = AWE == min(AWE[1:4])
    ),
    cells_body(
     columns = cmPk,
     row =  cmPk == max(cmPk[1:4])
     ),    
    cells_body(
     columns = BF,
     row =  BF > 10),
    cells_body(
     columns =  T11_VLMR_PValue,
     row =  T11_VLMR_PValue < .001),
    cells_body(
     columns =  BLRT_PValue,
     row =  BLRT_PValue < .001)
  )
) 

fit_table

```

------------------------------------------------------------------------

Save table:

```{r}
gtsave(fit_table, here("lab3","figures","fit_table.png"))

# This may or may not work, its a newer feature:
gtsave(fit_table, here("lab3", "figures", "fit_table.docx"))
```

------------------------------------------------------------------------

### Information Criteria Plot

```{r height=5, width=7}
allFit %>%
  dplyr::select(2:7) %>%
  rowid_to_column() %>%
  pivot_longer(`BIC`:`AWE`,
               names_to = "Index",
               values_to = "ic_value") %>%
  mutate(Index = factor(Index,
                        levels = c ("AWE", "CAIC", "BIC", "aBIC"))) %>%
  ggplot(aes(
    x = rowid,
    y = ic_value,
    color = Index,
    shape = Index,
    group = Index,
    lty = Index
  )) +
  geom_point(size = 2.0) + geom_line(size = .8) +
  scale_x_continuous(breaks = 1:nrow(allFit)) +
  scale_colour_grey(end = .5) +
  theme_cowplot() +
  labs(x = "Number of Classes", y = "Information Criteria Value", title = "Information Criteria") +
  theme(
    text = element_text(family = "serif", size = 12),
    legend.text = element_text(family="serif", size=12),
    legend.key.width = unit(3, "line"),
    legend.title = element_blank(),
    legend.position = "top"  
  )
```

------------------------------------------------------------------------

Save figure:

```{r}
ggsave(here("figures", "info_criteria.png"), dpi=300, height=5, width=7, units="in")
```

------------------------------------------------------------------------

### Compare Class Solutions

Compare probability plots for $K = 1:4$ class solutions

```{r}
model_results <- data.frame()

for (i in 1:length(output_lsal)) {
  
  temp <- output_lsal[[i]]$parameters$probability.scale %>%                                       mutate(model = paste0(i,"-Class Model"))
  
  model_results <- rbind(model_results, temp)
}

compare_plot <-
  model_results %>%
  filter(category == 2) %>%
  dplyr::select(est, model, LatentClass, param) %>% 
  filter(model != "5-Class Model" & model != "6-Class Model") #Remove from plot

compare_plot$param <- fct_inorder(compare_plot$param)

ggplot(
  compare_plot,
  aes(
    x = param,
    y = est,
    color = LatentClass,
    shape = LatentClass,
    group = LatentClass,
    lty = LatentClass
  )
) +
  geom_point() + 
  geom_line() +
  scale_colour_viridis_d() +
  facet_wrap( ~ model, ncol = 2) +
  labs(title = "Science Attitude Items",
       x = " ", y = "Probability") +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
                          axis.text.x = element_text(angle = -45, hjust = -.1))                            
```

------------------------------------------------------------------------

Save figure:

```{r, eval = FALSE}
ggsave(here("figures", "compare_kclass_plot.png"), dpi=300, height=5, width=7, units="in")
```

------------------------------------------------------------------------

### 4-Class Probability Plot

Use the `plot_lca` function provided in the folder to plot the item probability plot. This function requires one argument:
- `model_name`: The name of the Mplus `readModels` object (e.g., `output_lsal$c4_lsal.out`)

```{r fig.height=6, fig.width=10}
source("plot_lca.txt")

plot_lca(model_name = output_lsal$c4_lsal.out)
```

------------------------------------------------------------------------

Save figure:

```{r, eval = FALSE}
ggsave(here("figures", "probability_plot.png"), dpi="retina", height=5, width=7, units="in")
```


------------------------------------------------------------------------

### Observed Response Patterns

Save response frequencies for the 4-class model with `response is _____.dat` under `SAVEDATA.`

```{r, eval = FALSE}

patterns  <- mplusObject(
  
  TITLE = "LCA - Save response patterns", 
  
  VARIABLE = 
  "categorical = enjoy useful logical job adult; 
   usevar =  enjoy useful logical job adult;
   classes = c(4);",
  
  ANALYSIS = 
   "estimator = mlr; 
    type = mixture;    
    starts = 200 100; 
    processors = 10;
    optseed = 939021;",
  
  SAVEDATA = 
   "File=savedata.dat;
    Save=cprob;
    
    ! Code to save response frequency data 
    
    response is resp_patterns.dat;",
  
  OUTPUT = "patterns tech10 tech11 tech14",
  
  usevariables = colnames(lsay_data),
  rdata = lsay_data)

patterns_fit <- mplusModeler(patterns,
                dataout=here("lab3", "mplus", "patterns.dat"),
                modelout=here("lab3", "mplus", "patterns.inp") ,
                check=TRUE, run = TRUE, hashfilename = FALSE)
```

Note: You may see an error that says `<simpleError in bivarFitData[mPos, ] <- c(vars, values): number of items to replace is not a multiple of replacement length>`, the developers are aware of this and are working to fix it.

------------------------------------------------------------------------

Read in observed response pattern data and relabel the columns

```{r}
# Read in response frequency data that we just created:
patterns <- read_table(here("lab3", "mplus", "resp_patterns.dat"),
                        col_names=FALSE, na = "*") 

# Extract the column names
names <- names(readModels(here("lab3", "mplus", "patterns.out"))[['savedata']])

# Add the names back to the dataset
colnames(patterns) <- c("Frequency", names)  
```

Create a table with the top 5 unconditional response pattern, then top of conditional response pattern for each modal class assignment

```{r,eval=TRUE}
# Order responses by highest frequency
order_highest <- patterns %>% 
  arrange(desc(Frequency)) 

# Loop `patterns` data to list top 5 conditional response patterns for each class
loop_cond  <- lapply(1:max(patterns$C), function(k) {       
order_cond <- patterns %>%                    
  filter(C == k) %>%                    
  arrange(desc(Frequency)) %>%                
  head(5)                                     
  })                                          

# Convert loop into data frame
table_data <- as.data.frame(bind_rows(loop_cond))

# Combine unconditional and conditional responses patterns
response_patterns <-  rbind(order_highest[1:5,], table_data) 
```

Finally, use `{gt}` to make a nicely formatted table

```{r}
resp_table <- response_patterns %>% 
  gt() %>%
    tab_header(
    title = "Observed Response Patterns",
    subtitle = html("Response patterns, estimated frequencies, estimated posterior class probabilities and modal assignments")) %>% 
    tab_source_note(
    source_note = md("Data Source: **Longitudinal Study of Life (LSAL)**")) %>%
    cols_label(
      Frequency = html("<i>f</i><sub>r</sub>"),
    ENJOY = "Enjoy",
    USEFUL = "Useful",
    LOGICAL = "Logical",
    JOB = "Job",
    ADULT = "Adult",
    CPROB1 = html("P<sub><i>k</i></sub>=1"),
    CPROB2 = html("P<sub><i>k</i></sub>=2"),
    CPROB3 = html("P<sub><i>k</i></sub>=3"),
    CPROB4 = html("P<sub><i>k</i></sub>=4"),    
    C = md("*k*")) %>% 
  tab_row_group(
    label = "Unconditional response patterns",
    rows = 1:5) %>%
  tab_row_group(
    label = md("*k* = 1 Conditional response patterns"),
    rows = 6:10) %>% #EDIT THESE VALUES BASED ON THE LAST COLUMN
  tab_row_group(
    label = md("*k* = 2 Conditional response patterns"),
    rows = 11:15)  %>% #EDIT THESE VALUES BASED ON THE LAST COLUMN
  tab_row_group(
    label = md("*k* = 3 Conditional response patterns"),
    rows = 16:20)  %>% #EDIT THESE VALUES BASED ON THE LAST COLUMN
  tab_row_group(
    label = md("*k* = 4 Conditional response patterns"),
    rows = 21:25)  %>% #EDIT THESE VALUES BASED ON THE LAST COLUMN  
    row_group_order(
      groups = c("Unconditional response patterns",
                 md("*k* = 1 Conditional response patterns"),
                 md("*k* = 2 Conditional response patterns"),
                 md("*k* = 3 Conditional response patterns"),
                 md("*k* = 4 Conditional response patterns"))) %>% 
    tab_footnote(
    footnote = html(
      "<i>Note.</i> <i>f</i><sub>r</sub> = response pattern frequency; P<sub><i>k</i></sub> = posterior class probabilities"
    )
  ) %>% 
  cols_align(align = "center") %>% 
  opt_align_table_header(align = "left") %>% 
  gt::tab_options(table.font.names = "Times New Roman") 

resp_table
```

------------------------------------------------------------------------

Save table:

```{r}
gtsave(resp_table, here("lab3","figures","resp_table.png"))

# This may or may not work, its a newer feature:
gtsave(resp_table, here("lab3", "figures", "resp_table.docx"))
```


------------------------------------------------------------------------

### Classification Diagnostics

Use Mplus to calculate k-class confidence intervals (Note: Change the syntax to make your chosen *k*-class model):

```{r, eval=FALSE}
classification  <- mplusObject(
  
  TITLE = "LCA - Calculated k-Class 95% CI",
  
  VARIABLE =
    "categorical = enjoy-adult;
   usevar =  enjoy-adult;
   classes = c(4);", 
  
  ANALYSIS =
    "estimator = ml;
    type = mixture;
    starts = 200 100; 
    processors = 10;
    optseed = 939021;
    bootstrap = 1000;",
  
  MODEL =
    "
  !CHANGE THIS SECTION TO YOUR CHOSEN k-CLASS MODEL
    
  %OVERALL%
  [C#1](c1);
  [C#2](c2);
  [C#3](c3);


  Model Constraint:
  New(p1 p2 p3 p4);
  
  p1 = exp(c1)/(1+exp(c1)+exp(c2)+(c3));
  p2 = exp(c2)/(1+exp(c1)+exp(c2)+(c3));
  p3 = exp(c3)/(1+exp(c1)+exp(c2)+(c3));  
  p4 = 1/(1+exp(c1)+exp(c2)+(c3));",

  
  OUTPUT = "cinterval(bcbootstrap)",
  
  usevariables = colnames(lsay_data),
  rdata = lsay_data)

classification_fit <- mplusModeler(classification,
                dataout=here("lab3","mplus", "lsal.dat"),
                modelout=here("lab3", "mplus", "class.inp") ,
                check=TRUE, run = TRUE, hashfilename = FALSE)
```

*Note*: Ensure that the classes did not shift during this step (i.g., Class 1 in the enumeration run is now Class 4). Evaluate output and compare the class counts and proportions for the latent classes. Using the OPTSEED function ensures replication of the best loglikelihood value run.  

------------------------------------------------------------------------

Read in the 4-class model:

```{r}
# Read in the 4-class model and extract information needed
class_output <- readModels(here("lab3", "mplus", "class.out"))

# Entropy
entropy <- c(class_output$summaries$Entropy, rep(NA, class_output$summaries$NLatentClasses-1))

# 95% k-Class and k-class 95% Confidence Intervals
k_ci <- class_output$parameters$ci.unstandardized %>% 
  filter(paramHeader == "New.Additional.Parameters") %>% 
  unite(CI, c(low2.5,up2.5), sep=", ", remove = TRUE) %>% 
  mutate(CI = paste0("[", CI, "]")) %>% 
  rename(kclass=est) %>% 
  dplyr::select(kclass, CI)

# AvePPk = Average Latent Class Probabilities for Most Likely Latent Class Membership (Row) by Latent Class (Column)
avePPk <- tibble(avePPk = diag(class_output$class_counts$avgProbs.mostLikely))

# mcaPk = modal class assignment proportion 
mcaPk <- round(class_output$class_counts$mostLikely,3) %>% 
  mutate(model = paste0("Class ", class)) %>% 
  add_column(avePPk, k_ci) %>% 
  rename(mcaPk = proportion) %>% 
  dplyr::select(model, kclass, CI, mcaPk, avePPk)

# OCCk = odds of correct classification
OCCk <- mcaPk %>% 
  mutate(OCCk = round((avePPk/(1-avePPk))/(kclass/(1-kclass)),3))

# Put everything together
class_df <- data.frame(OCCk, entropy)
```

Now, use `{gt}` to make a nicely formatted table

```{r}
class_table <- class_df %>% 
  gt() %>%
    tab_header(
    title = "Model Classification Diagnostics for the 4-Class Solution") %>%
    cols_label(
      model = md("*k*-Class"),
      kclass = md("*k*-Class Proportions"),
      CI = "95% CI",
      mcaPk = md("*mcaPk*"),
      avePPk = md("*AvePPk*"),
      OCCk = md("*OCCk*"),
      entropy = "Entropy") %>% 
    sub_missing(7,
              missing_text = "") %>%
    tab_footnote(
    footnote = html(
      "<i>Note.</i> <i>f</i><sub>r</sub> = response pattern frequency; P<sub><i>k</i></sub> = posterior class probabilities"
    )
  ) %>% 
  cols_align(align = "center") %>% 
  opt_align_table_header(align = "left") %>% 
  gt::tab_options(table.font.names = "Times New Roman")

class_table
```


------------------------------------------------------------------------

Save table:

```{r}
gtsave(class_table, here("lab3","figures","class_table.png"))

# This may or may not work, its a newer feature:
gtsave(class_table, here("lab3", "figures", "class_table.docx"))
```






